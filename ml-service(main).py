import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from ultralytics import YOLO
import cv2
import threading
import time
import queue
import os
import csv
import numpy as np
import json
import subprocess
import sys
from datetime import datetime
import uuid
import tensorflow as tf
from tensorflow.keras.models import load_model
import math


class YOLOApp:
    def __init__(self, root, config=None):
        self.root = root
        self.root.title("YOLOv8 Pose Tracker - –ü—Ä–∏—Å–µ–¥–∞–Ω–∏—è")
        self.root.geometry("900x700")
        self.root.configure(bg="#f0f0f0")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.config = config or self.load_config()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        model_paths = {
            'nano': 'yolov8n-pose.pt',
            'medium': 'yolov8m-pose.pt',
            'large': 'yolov8l-pose.pt'
        }

        model_path = model_paths.get(self.config['model_size'], 'yolov8n-pose.pt')
        self.model = YOLO(model_path)

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        device = 'cuda' if self.config['use_gpu'] and self.check_cuda_available() else 'cpu'
        self.model.to(device)
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.is_recording = False
        self.is_processing_video = False
        self.start_time = None
        self.video_writer = None
        self.cap = None
        self.frame_queue = queue.Queue(maxsize=10)
        self.csv_file = None
        self.csv_writer = None
        self.squat_model = None
        self.features_mean = None
        self.features_std = None
        self.sequence_length = 30
        self.feature_sequence = []

        # –ü—É—Ç—å –∫ CSV-—Ñ–∞–π–ª—É
        self.csv_path = 'keypoints.csv'

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π
        self.check_squat_model()

        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        self.create_widgets()

        # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–∞–π–º–µ—Ä–∞
        self.update_timer()

    def load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        default_config = {
            'model_size': 'nano',
            'resolution': [640, 480],
            'fps': 20,
            'use_gpu': True
        }

        if os.path.exists('config.json'):
            try:
                with open('config.json', 'r') as f:
                    return json.load(f)
            except:
                pass
        return default_config

    def check_cuda_available(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ CUDA"""
        try:
            import torch
            return torch.cuda.is_available()
        except:
            return False

    def check_squat_model(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π"""
        try:
            model_path = os.path.join(os.path.dirname(__file__), 'squat_model.h5')
            mean_path = os.path.join(os.path.dirname(__file__), 'features_mean.npy')
            std_path = os.path.join(os.path.dirname(__file__), 'features_std.npy')

            if os.path.exists(model_path) and os.path.exists(mean_path) and os.path.exists(std_path):
                self.squat_model = load_model(model_path)
                self.features_mean = np.load(mean_path)
                self.features_std = np.load(std_path)
                self.squat_status = "–ì–æ—Ç–æ–≤–æ"
                self.squat_color = "green"
            else:
                self.squat_status = "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
                self.squat_color = "red"
                print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–ª—è —Ä–∞–±–æ—Ç—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å.")
        except Exception as e:
            self.squat_status = f"–û—à–∏–±–∫–∞: {str(e)}"
            self.squat_color = "red"
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")

    def create_widgets(self):
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_frame = ttk.Frame(self.root)
        title_frame.pack(pady=10)
        title_label = ttk.Label(title_frame, text="–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π", font=('Arial', 16, 'bold'))
        title_label.pack()

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        model_info = ttk.Frame(self.root)
        model_info.pack(pady=5)
        ttk.Label(model_info, text=f"–ú–æ–¥–µ–ª—å YOLO: {self.config['model_size']} | ", font=('Arial', 10)).pack(
            side=tk.LEFT)
        ttk.Label(model_info, text=f"–°—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π: {self.squat_status}",
                  foreground=self.squat_color, font=('Arial', 10, 'bold')).pack(side=tk.LEFT)

        # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∫–Ω–æ–ø–æ–∫
        button_frame = ttk.Frame(self.root)
        button_frame.pack(pady=10)

        # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞/–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏
        self.record_btn = ttk.Button(button_frame, text="‚ñ∂ –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å",
                                     command=self.toggle_recording, width=20)
        self.record_btn.pack(side=tk.LEFT, padx=5)

        # –ö–Ω–æ–ø–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ—Ç–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ
        self.process_video_btn = ttk.Button(button_frame, text="üé¨ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ",
                                            command=self.process_existing_video, width=20)
        self.process_video_btn.pack(side=tk.LEFT, padx=5)

        # –ö–Ω–æ–ø–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        self.train_btn = ttk.Button(button_frame, text="üìö –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å",
                                    command=self.train_model, width=20)
        self.train_btn.pack(side=tk.LEFT, padx=5)

        # –¢–∞–π–º–µ—Ä
        self.timer_label = ttk.Label(button_frame, text="00:00:00",
                                     font=('Arial', 14, 'bold'), foreground="blue")
        self.timer_label.pack(side=tk.LEFT, padx=10)

        # –ú–µ—Ç–∫–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–∏–¥–µ–æ
        self.video_label = ttk.Label(self.root, background="black", relief="solid", borderwidth=1)
        self.video_label.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–ø–∏—Å–∏
        self.status_label = ttk.Label(self.root, text="–ì–æ—Ç–æ–≤–æ", font=('Arial', 10), foreground="gray")
        self.status_label.pack(side=tk.BOTTOM, pady=5)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_text = f"–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {self.config['resolution'][0]}x{self.config['resolution'][1]} | FPS: {self.config['fps']}"
        config_label = ttk.Label(self.root, text=config_text, font=('Arial', 9), foreground="gray")
        config_label.pack(side=tk.BOTTOM, pady=2)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞–±–æ—Ç–µ
        info_frame = ttk.Frame(self.root)
        info_frame.pack(fill=tk.X, padx=10, pady=5)
        ttk.Label(info_frame, text="–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:", font=('Arial', 10, 'bold')).pack(anchor=tk.W)
        info_text = "1. –ù–∞–∂–º–∏—Ç–µ '–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å', —á—Ç–æ–±—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π\n" \
                    "2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ '–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å' –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä–æ–π\n" \
                    "3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ '–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ' –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≥–æ—Ç–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞\n" \
                    "4. –î–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–∫—Ä–∏–ø—Ç collect_data.py"
        ttk.Label(info_frame, text=info_text, justify=tk.LEFT, wraplength=850).pack(anchor=tk.W)

    def toggle_recording(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∑–∞–ø–∏—Å–∏"""
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()

    def start_recording(self):
        """–ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ –∏ CSV"""
        if self.is_processing_video:
            self.show_error("–°–Ω–∞—á–∞–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ!")
            return

        self.is_recording = True
        self.start_time = time.time()
        self.record_btn.config(text="‚ñ† –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å")
        self.process_video_btn.config(state='disabled')
        self.train_btn.config(state='disabled')
        self.status_label.config(text="–ó–∞–ø–∏—Å—å –≤–µ–¥—ë—Ç—Å—è...", foreground="red")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            self.show_error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É!")
            return

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã
        width, height = self.config['resolution']
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)

        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–∞–¥—Ä–∞
        ret, frame = self.cap.read()
        if not ret:
            self.show_error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã!")
            return

        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤
        video_filename, csv_filename = self.generate_unique_filenames()

        # –°–æ–∑–¥–∞–µ–º VideoWriter
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        self.video_writer = cv2.VideoWriter(
            video_filename, fourcc, self.config['fps'],
            (frame.shape[1], frame.shape[0])
        )

        # –°–æ–∑–¥–∞–µ–º CSV-—Ñ–∞–π–ª
        self.csv_file = open(csv_filename, 'w', newline='', encoding='utf-8')
        self.csv_writer = csv.writer(self.csv_file)
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ CSV: frame_time, point_0_x, point_0_y, ..., point_16_x, point_16_y
        headers = ['timestamp'] + [f'point_{i}_{coord}' for i in range(17) for coord in ['x', 'y']]
        self.csv_writer.writerow(headers)

        # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
        self.process_thread = threading.Thread(
            target=self.process_camera_video,
            daemon=True
        )
        self.process_thread.start()

    def stop_recording(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ –∏ CSV"""
        self.is_recording = False
        self.record_btn.config(text="‚ñ∂ –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å")
        self.process_video_btn.config(state='normal')
        self.train_btn.config(state='normal')
        self.status_label.config(text="–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞", foreground="gray")

        # –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
        if hasattr(self, 'cap'):
            self.cap.release()
        if hasattr(self, 'video_writer'):
            self.video_writer.release()
        if hasattr(self, 'csv_file') and self.csv_file:
            self.csv_file.close()

    def process_existing_video(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ—Ç–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞"""
        if self.is_recording:
            self.show_error("–°–Ω–∞—á–∞–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–ø–∏—Å—å!")
            return

        # –û—Ç–∫—Ä—ã—Ç–∏–µ –¥–∏–∞–ª–æ–≥–∞ –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–∞
        file_path = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª",
            filetypes=[
                ("–í–∏–¥–µ–æ —Ñ–∞–π–ª—ã", "*.mp4 *.avi *.mov *.mkv"),
                ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")
            ]
        )

        if not file_path:
            return

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        if not os.path.exists(file_path):
            self.show_error("–í—ã–±—Ä–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
            return

        self.is_processing_video = True
        self.process_video_btn.config(text="‚èπ –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É")
        self.record_btn.config(state='disabled')
        self.train_btn.config(state='disabled')
        self.status_label.config(text="–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ...", foreground="orange")

        # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
        self.process_thread = threading.Thread(
            target=self.process_video_file,
            args=(file_path,),
            daemon=True
        )
        self.process_thread.start()

    def stop_video_processing(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ"""
        self.is_processing_video = False
        self.process_video_btn.config(text="üé¨ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ")
        self.record_btn.config(state='normal')
        self.train_btn.config(state='normal')
        self.status_label.config(text="–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞", foreground="gray")

        # –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
        if hasattr(self, 'cap'):
            self.cap.release()
        if hasattr(self, 'video_writer'):
            self.video_writer.release()
        if hasattr(self, 'csv_file') and self.csv_file:
            self.csv_file.close()

    def process_camera_video(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã"""
        while self.is_recording:
            ret, frame = self.cap.read()
            if not ret:
                break

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
            device = 'cuda' if self.config['use_gpu'] and self.check_cuda_available() else 'cpu'
            results = self.model(frame, device=device)
            annotated_frame = results[0].plot()

            # –ó–∞–ø–∏—Å—å –≤ –≤–∏–¥–µ–æ—Ñ–∞–π–ª
            self.video_writer.write(annotated_frame)

            # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏
            keypoints = results[0].keypoints.xy.cpu().numpy()  # shape: [num_people, 17, 2]
            timestamp = time.time() - self.start_time

            # –ó–∞–ø–∏—Å—å –≤ CSV: —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–∞—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–∞—è –ø–µ—Ä—Å–æ–Ω–∞
            if len(keypoints) > 0:
                row = [f"{timestamp:.3f}"]  # –í—Ä–µ–º—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é 0.001
                for x, y in keypoints[0]:  # –ü–µ—Ä–≤–∞—è –ø–µ—Ä—Å–æ–Ω–∞, 17 —Ç–æ—á–µ–∫
                    row.extend([f"{x:.3f}", f"{y:.3f}"])
                self.csv_writer.writerow(row)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π
            if len(keypoints) > 0 and self.squat_model is not None:
                kp = keypoints[0]  # –ü–µ—Ä–≤–∞—è –ø–µ—Ä—Å–æ–Ω–∞
                features = self.calculate_squat_features(kp)

                if features is not None:
                    self.feature_sequence.append(features)

                    # –ï—Å–ª–∏ –Ω–∞–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    if len(self.feature_sequence) >= self.sequence_length:
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ
                        features_array = np.array(self.feature_sequence[-self.sequence_length:])
                        features_normalized = (features_array - self.features_mean) / self.features_std

                        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è batch
                        features_normalized = np.expand_dims(features_normalized, axis=0)

                        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                        prediction = self.squat_model.predict(features_normalized)
                        is_correct = prediction[0][0] > 0.5

                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –∫–∞–¥—Ä
                        text = "‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ" if is_correct else "‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ"
                        color = (0, 255, 0) if is_correct else (0, 0, 255)
                        annotated_frame = cv2.putText(
                            annotated_frame,
                            text,
                            (50, 50),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            1,
                            color,
                            2
                        )

            # –ü–µ—Ä–µ–¥–∞—á–∞ –∫–∞–¥—Ä–∞ –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            try:
                self.frame_queue.put_nowait(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))
            except queue.Full:
                pass

        # –û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        if hasattr(self, 'cap'):
            self.cap.release()
        if hasattr(self, 'video_writer'):
            self.video_writer.release()
        if hasattr(self, 'csv_file') and self.csv_file:
            self.csv_file.close()

    def process_video_file(self, video_path):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ—Ç–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞
            self.cap = cv2.VideoCapture(video_path)
            if not self.cap.isOpened():
                self.show_error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ —Ñ–∞–π–ª!")
                self.stop_video_processing()
                return

            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            fps = int(self.cap.get(cv2.CAP_PROP_FPS))
            total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            video_filename, csv_filename = self.generate_unique_filenames(prefix="processed_")

            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –ø–µ—Ä–≤–æ–≥–æ –∫–∞–¥—Ä–∞
            ret, first_frame = self.cap.read()
            if not ret:
                self.show_error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä –∏–∑ –≤–∏–¥–µ–æ!")
                self.stop_video_processing()
                return

            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –Ω–∞—á–∞–ª—É

            # –°–æ–∑–¥–∞–µ–º VideoWriter
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            self.video_writer = cv2.VideoWriter(
                video_filename, fourcc, fps,
                (first_frame.shape[1], first_frame.shape[0])
            )

            # –°–æ–∑–¥–∞–µ–º CSV-—Ñ–∞–π–ª
            self.csv_file = open(csv_filename, 'w', newline='', encoding='utf-8')
            self.csv_writer = csv.writer(self.csv_file)
            headers = ['frame_number'] + [f'point_{i}_{coord}' for i in range(17) for coord in ['x', 'y']]
            self.csv_writer.writerow(headers)

            frame_count = 0
            start_time = time.time()

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤
            while self.is_processing_video:
                ret, frame = self.cap.read()
                if not ret:
                    break

                frame_count += 1

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
                device = 'cuda' if self.config['use_gpu'] and self.check_cuda_available() else 'cpu'
                results = self.model(frame, device=device)
                annotated_frame = results[0].plot()

                # –ó–∞–ø–∏—Å—å –≤ –≤–∏–¥–µ–æ—Ñ–∞–π–ª
                self.video_writer.write(annotated_frame)

                # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏
                keypoints = results[0].keypoints.xy.cpu().numpy()

                # –ó–∞–ø–∏—Å—å –≤ CSV: —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–∞—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–∞—è –ø–µ—Ä—Å–æ–Ω–∞
                if len(keypoints) > 0:
                    row = [frame_count]
                    for x, y in keypoints[0]:  # –ü–µ—Ä–≤–∞—è –ø–µ—Ä—Å–æ–Ω–∞, 17 —Ç–æ—á–µ–∫
                        row.extend([f"{x:.3f}", f"{y:.3f}"])
                    self.csv_writer.writerow(row)

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π
                if len(keypoints) > 0 and self.squat_model is not None:
                    kp = keypoints[0]  # –ü–µ—Ä–≤–∞—è –ø–µ—Ä—Å–æ–Ω–∞
                    features = self.calculate_squat_features(kp)

                    if features is not None:
                        self.feature_sequence.append(features)

                        # –ï—Å–ª–∏ –Ω–∞–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                        if len(self.feature_sequence) >= self.sequence_length:
                            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ
                            features_array = np.array(self.feature_sequence[-self.sequence_length:])
                            features_normalized = (features_array - self.features_mean) / self.features_std

                            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è batch
                            features_normalized = np.expand_dims(features_normalized, axis=0)

                            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                            prediction = self.squat_model.predict(features_normalized)
                            is_correct = prediction[0][0] > 0.5

                            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –∫–∞–¥—Ä
                            text = "‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ" if is_correct else "‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ"
                            color = (0, 255, 0) if is_correct else (0, 0, 255)
                            annotated_frame = cv2.putText(
                                annotated_frame,
                                text,
                                (50, 50),
                                cv2.FONT_HERSHEY_SIMPLEX,
                                1,
                                color,
                                2
                            )

                # –ü–µ—Ä–µ–¥–∞—á–∞ –∫–∞–¥—Ä–∞ –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                try:
                    self.frame_queue.put_nowait(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))
                except queue.Full:
                    pass

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
                if frame_count % 30 == 0:  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 30 –∫–∞–¥—Ä–æ–≤
                    elapsed_time = time.time() - start_time
                    progress = (frame_count / total_frames) * 100
                    self.status_label.config(text=f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {progress:.1f}%")

            # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            self.stop_video_processing()

            if frame_count > 0:
                processing_time = time.time() - start_time
                print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f} —Å–µ–∫—É–Ω–¥")
                print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {frame_count} –∫–∞–¥—Ä–æ–≤")
                print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
                print(f"  –í–∏–¥–µ–æ: {video_filename}")
                print(f"  CSV: {csv_filename}")

        except Exception as e:
            self.show_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {str(e)}")
            self.stop_video_processing()

    def calculate_squat_features(self, keypoints):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—Å–µ–¥–∞–Ω–∏–π"""
        # keypoints: numpy array shape [17, 2] (–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ç–æ—á–µ–∫)
        features = []

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ç–æ—á–µ–∫
        if len(keypoints) < 17:
            return None

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —É–≥–ª–∞ –º–µ–∂–¥—É —Ç—Ä–µ–º—è —Ç–æ—á–∫–∞–º–∏
        def calculate_angle(a, b, c):
            a = np.array(a)
            b = np.array(b)
            c = np.array(c)
            ba = a - b
            bc = c - b
            cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
            angle = np.arccos(cosine_angle)
            return np.degrees(angle)

        # –¢–∞–∑: —Å—Ä–µ–¥–Ω–µ–µ –º–µ–∂–¥—É –ø—Ä–∞–≤—ã–º –∏ –ª–µ–≤—ã–º –±–µ–¥—Ä–æ–º (—Ç–æ—á–∫–∏ 11 –∏ 12)
        hip_center = (keypoints[11] + keypoints[12]) / 2

        # 1. –£–≥–æ–ª –ø—Ä–∞–≤–æ–≥–æ –∫–æ–ª–µ–Ω–∞ (–º–µ–∂–¥—É –±–µ–¥—Ä–æ–º, –∫–æ–ª–µ–Ω–æ, –ª–æ–¥—ã–∂–∫–∞)
        right_knee = calculate_angle(keypoints[11], keypoints[13], keypoints[15])

        # 2. –£–≥–æ–ª –ª–µ–≤–æ–≥–æ –∫–æ–ª–µ–Ω–∞
        left_knee = calculate_angle(keypoints[12], keypoints[14], keypoints[16])

        # 3. –£–≥–æ–ª –ø—Ä–∞–≤–æ–≥–æ –±–µ–¥—Ä–∞ (–º–µ–∂–¥—É —Ç–∞–∑–æ–º, –±–µ–¥—Ä–æ, –∫–æ–ª–µ–Ω–æ)
        right_hip = calculate_angle(hip_center, keypoints[11], keypoints[13])

        # 4. –£–≥–æ–ª –ª–µ–≤–æ–≥–æ –±–µ–¥—Ä–∞
        left_hip = calculate_angle(hip_center, keypoints[12], keypoints[14])

        # 5. –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–æ–ª–µ–Ω—è–º–∏
        dist_knees = np.linalg.norm(keypoints[13] - keypoints[14])

        # 6. –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Å—Ç—É–ø–Ω—è–º–∏
        dist_feet = np.linalg.norm(keypoints[15] - keypoints[16])

        # 7. –ì–ª—É–±–∏–Ω–∞ –ø—Ä–∏—Å–µ–¥–∞ (—Ä–∞–∑–Ω–∏—Ü–∞ Y –º–µ–∂–¥—É —Ç–∞–∑–æ–º –∏ —Å—Ä–µ–¥–Ω–µ–π –ª–æ–¥—ã–∂–∫–æ–π)
        ankle_y = (keypoints[15][1] + keypoints[16][1]) / 2
        depth = hip_center[1] - ankle_y

        # 8. –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∫–æ–ª–µ–Ω–µ–π –æ—Ç –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ (–¥–ª—è –ø—Ä–∞–≤–æ–π –Ω–æ–≥–∏)
        knee_deviation = abs(keypoints[13][0] - keypoints[11][0])

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≥–ª—É–±–∏–Ω—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–æ—Å—Ç–∞ (–ø—Ä–∏–º–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
        if keypoints[11][1] > 0 and keypoints[12][1] > 0:
            height_estimate = max(keypoints[11][1], keypoints[12][1]) - min(keypoints[15][1], keypoints[16][1])
            if height_estimate > 0:
                depth = depth / height_estimate

        features = [
            right_knee, left_knee, right_hip, left_hip,
            dist_knees, dist_feet, depth, knee_deviation
        ]

        return features

    def generate_unique_filenames(self, prefix=""):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤"""
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –Ω–∞ —Ä–∞–±–æ—á–µ–º —Å—Ç–æ–ª–µ
        desktop_path = os.path.join(os.path.expanduser("~"), "Desktop")
        records_folder = os.path.join(desktop_path, "–ó–∞–ø–∏—Å–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏")

        if not os.path.exists(records_folder):
            os.makedirs(records_folder)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä
        base_name = f"{prefix}{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        video_filename = os.path.join(records_folder, f"{base_name}.mp4")
        csv_filename = os.path.join(records_folder, f"{base_name}.csv")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä
        counter = 1
        original_video = video_filename
        original_csv = csv_filename

        while os.path.exists(video_filename) or os.path.exists(csv_filename):
            name_without_ext = os.path.splitext(os.path.basename(original_video))[0]
            video_filename = os.path.join(records_folder, f"{name_without_ext}_{counter}.mp4")
            csv_filename = os.path.join(records_folder, f"{name_without_ext}_{counter}.csv")
            counter += 1

        return video_filename, csv_filename

    def update_timer(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–∞–π–º–µ—Ä–∞ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤"""
        if self.is_recording:
            elapsed = int(time.time() - self.start_time)
            hours, rem = divmod(elapsed, 3600)
            mins, secs = divmod(rem, 60)
            self.timer_label.config(text=f"{hours:02}:{mins:02}:{secs:02}")

        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –Ω–æ–≤—ã–π –∫–∞–¥—Ä –∏–∑ –æ—á–µ—Ä–µ–¥–∏
        try:
            frame = self.frame_queue.get_nowait()
            self.display_frame(frame)
        except queue.Empty:
            pass

        # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –≤—ã–∑–æ–≤ —á–µ—Ä–µ–∑ 33 –º—Å (~30 FPS)
        self.root.after(33, self.update_timer)

    def display_frame(self, frame):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–¥—Ä–∞ –≤ Label —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PIL"""
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∫–∞–¥—Ä
        img_resized = self.resize_frame(frame)

        # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç Image –∏–∑ –º–∞—Å—Å–∏–≤–∞
        pil_image = Image.fromarray(img_resized)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PhotoImage –¥–ª—è Tkinter
        photo = ImageTk.PhotoImage(image=pil_image)

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∫—É
        self.video_label.config(image=photo)
        self.video_label.image = photo  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Å—ã–ª–∫—É, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–±–æ—Ä–∫–∏ –º—É—Å–æ—Ä–∞

    def resize_frame(self, frame):
        """–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–¥—Ä–∞ –ø–æ–¥ —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞"""
        width = self.video_label.winfo_width()
        height = self.video_label.winfo_height()

        if width <= 0 or height <= 0:
            return frame  # –ù–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º, –µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã –Ω–µ –∏–∑–≤–µ—Å—Ç–Ω—ã

        aspect_ratio = frame.shape[1] / frame.shape[0]
        new_width = min(width, int(height * aspect_ratio))
        new_height = min(height, int(width / aspect_ratio))

        return cv2.resize(frame, (new_width, new_height))

    def show_error(self, message):
        """–ü–æ–∫–∞–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ"""
        error_window = tk.Toplevel(self.root)
        error_window.title("–û—à–∏–±–∫–∞")
        ttk.Label(error_window, text=message, padding=20).pack()
        ttk.Button(error_window, text="OK", command=error_window.destroy).pack(pady=10)

    def train_model(self):
        """–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
        if self.is_recording or self.is_processing_video:
            self.show_error("–°–Ω–∞—á–∞–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–ø–∏—Å—å –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ!")
            return

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ
        try:
            subprocess.Popen([sys.executable, 'train_squat_model.py'])
            self.show_info("–ó–∞–ø—É—â–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")
        except Exception as e:
            self.show_error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –æ–±—É—á–µ–Ω–∏—è: {str(e)}")

    def show_info(self, message):
        """–ü–æ–∫–∞–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        info_window = tk.Toplevel(self.root)
        info_window.title("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        ttk.Label(info_window, text=message, padding=20).pack()
        ttk.Button(info_window, text="OK", command=info_window.destroy).pack(pady=10)


def check_models():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–µ–π"""
    models = ['yolov8n-pose.pt', 'yolov8m-pose.pt', 'yolov8l-pose.pt']
    missing_models = []

    for model in models:
        if not os.path.exists(model):
            missing_models.append(model)

    if missing_models:
        print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –º–æ–¥–µ–ª–∏:")
        for model in missing_models:
            print(f"  - {model}")
        print("–°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª–∏ —Å https://github.com/ultralytics/ultralytics/releases")
        return False
    return True


def run_configuration():
    """–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ config.json
        if not os.path.exists('config.json'):
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            default_config = {
                'model_size': 'nano',
                'resolution': [640, 480],
                'fps': 20,
                'use_gpu': True
            }
            with open('config.json', 'w') as f:
                json.dump(default_config, f, indent=4)
            print("–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ config.json")
        return True
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return False


if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–µ–π
    if not check_models():
        exit(1)

    # –ó–∞–ø—É—Å–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    print("–ó–∞–ø—É—Å–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
    if not run_configuration():
        print("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é...")

    root = tk.Tk()
    app = YOLOApp(root)
    root.mainloop()